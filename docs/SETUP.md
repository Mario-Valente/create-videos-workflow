# SETUP.md - Guia de InstalaÃ§Ã£o

## âš¡ InstalaÃ§Ã£o RÃ¡pida (Mac)

### 1. PrÃ©-requisitos
- macOS 12+
- Homebrew instalado
- Python 3.10+

### 2. InstalaÃ§Ã£o das DependÃªncias

#### **Passo 1: Ferramentas do Sistema**

```bash
# Instalar com Homebrew
brew install ollama ffmpeg python@3.11
```

#### **Passo 2: Python Virtual Environment**

```bash
cd create-videos-workflows
python3.11 -m venv venv
source venv/bin/activate
```

#### **Passo 3: DependÃªncias Python Base**

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

#### **Passo 4: Piper TTS (CLI - Recomendado para Mac)**

**OpÃ§Ã£o A: BinÃ¡rio PrÃ©-compilado (â­ Recomendado)**
```bash
# Download do binÃ¡rio para macOS ARM64 (M1/M2/M3)
mkdir -p ~/piper-bin
cd ~/piper-bin
curl -L -o piper.tar.gz "https://github.com/rhasspy/piper/releases/download/2024.01.30/piper_macos_arm64.tar.gz"
tar -xzf piper.tar.gz

# Adicionar ao PATH
export PATH="$HOME/piper-bin/piper/bin:$PATH"
echo 'export PATH="$HOME/piper-bin/piper/bin:$PATH"' >> ~/.zshrc

# Verificar
piper --version
```

**Ou OpÃ§Ã£o B: Python package (menos recomendado)**
```bash
pip install piper-tts
# Pode ter warnings de dependÃªncias, mas CLI funcionarÃ¡
```

#### **Passo 5: Modelos do Piper (PortuguÃªs)**

```bash
# Criar diretÃ³rio para modelos
mkdir -p ~/.local/share/piper

# Baixar vozes portuguÃªs
cd ~/.local/share/piper

# OpÃ§Ã£o 1: Voz feminina mais natural (recomendado)
wget https://huggingface.co/rhasspy/piper-voices/resolve/main/pt/pt_BR/faber/medium/pt_BR-faber-medium.onnx
wget https://huggingface.co/rhasspy/piper-voices/resolve/main/pt/pt_BR/faber/medium/pt_BR-faber-medium.onnx.json

# OpÃ§Ã£o 2: Voz feminina com variaÃ§Ãµes
wget https://huggingface.co/rhasspy/piper-voices/resolve/main/pt/pt_BR/faber/high/pt_BR-faber-high.onnx
wget https://huggingface.co/rhasspy/piper-voices/resolve/main/pt/pt_BR/faber/high/pt_BR-faber-high.onnx.json
```

#### **Passo 6: DependÃªncias Opcionais**

```bash
pip install librosa Pillow pyyaml requests
```

#### **Passo 7: Modelos Ollama**

```bash
# Em outro terminal, inicie Ollama
ollama serve &

# Em outro terminal, baixe modelos
ollama pull mistral
ollama pull llama2
```

#### **VerificaÃ§Ã£o RÃ¡pida**

```bash
# Verificar Piper
piper --version

# Verificar Ollama
curl http://localhost:11434/api/tags

# Verificar FFmpeg
ffmpeg -version | head -n 1
```

### 3. Configurar Stable Diffusion (Opcional mas recomendado)

```bash
# Clone a WebUI
cd ~
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
cd stable-diffusion-webui

# Baixe o modelo (este passo Ã© demorado: 10-20GB)
# A WebUI vai fazer isso automaticamente na primeira execuÃ§Ã£o

# Inicie em um terminal separado:
./webui-user.sh
# Acesse: http://127.0.0.1:7860
```

## ğŸ“‹ Verificar InstalaÃ§Ã£o

```bash
# Testar dependÃªncias
make test

# Verificar Ollama
make check-server

# Verificar Stable Diffusion
make check-sd
```

## ğŸš€ Uso BÃ¡sico

### Executar Pipeline Completa

```bash
# Ativar venv
source venv/bin/activate

# Executar com tema especÃ­fico
python orchestrator.py --topic "InteligÃªncia Artificial"

# Ou usar Makefile
make full TOPIC="InteligÃªncia Artificial"
```

### Executar Steps Individuais

```bash
# Step 1: Planejamento
python scripts/01_plan.py --topic "Seu tema" --output output/meu_video

# Step 2: Roteiro
python scripts/02_script.py --output output/meu_video

# Step 3: NarraÃ§Ã£o
python scripts/03_voice.py --output output/meu_video

# Step 4: Prompts de Imagem
python scripts/04_image_prompts.py --output output/meu_video

# Step 5: Gerar Imagens
python scripts/05_generate_images.py --output output/meu_video

# Step 6: Legendas
python scripts/06_subtitles.py --output output/meu_video

# Step 7: ComposiÃ§Ã£o de VÃ­deo
python scripts/07_compose_video.py --project output/meu_video
```

## âš™ï¸ ConfiguraÃ§Ãµes Importantes

### Modelos Ollama

Por padrÃ£o, usamos **Mistral** (rÃ¡pido). Alternativas:

```yaml
# config/models.yaml - modifique para usar:
ollama_model: "llama2"      # Mais preciso, mais lento
ollama_model: "neural-chat" # Mais rÃ¡pido, menor qualidade
```

### Qualidade de Imagens

**Modo RÃ¡pido** (15 steps, ~2-3 min por imagem):
```bash
python scripts/05_generate_images.py --output output/meu_video --fast
```

**Modo Qualidade** (25 steps, ~5-10 min):
```bash
python scripts/05_generate_images.py --output output/meu_video
```

### Velocidade de NarraÃ§Ã£o

Edite em `scripts/03_voice.py`:
```python
# PadrÃ£o: "faber-medium" (~150 palavras/min)
# OpÃ§Ãµes: "faber-medium", "faber-large" (mais natural)
```

## ğŸ”§ Troubleshooting

### Ollama nÃ£o encontrado
```bash
# Instalado?
which ollama

# Se nÃ£o: brew install ollama

# Se instalado, verificar se estÃ¡ rodando:
curl http://localhost:11434/api/tags

# Se erro, inicie: ollama serve
```

### Stable Diffusion nÃ£o encontrado
```bash
# Verificar se estÃ¡ rodando:
curl http://127.0.0.1:7860/config

# Se erro, inicie em outro terminal:
cd ~/stable-diffusion-webui && ./webui-user.sh
```

### Erro de dependÃªncias Python
```bash
# Reativar venv e reinstalar
source venv/bin/activate
pip install --upgrade -r requirements.txt
```

### Erro de timeout em geraÃ§Ã£o de imagens
- Aumente timeout em `config/models.yaml` (timeouts.sd_generate)
- Use menos steps (--fast)
- Reduza resoluÃ§Ã£o em `config/models.yaml`

## ğŸ“Š Requisitos de Hardware (Mac)

| Hardware | Tempo Total | Qualidade |
|----------|-------------|-----------|
| M1/M2    | 15-25 min   | Boa      |
| M1/M2 Pro| 10-15 min   | Muito Boa|
| M3/M3 Max| 5-10 min    | Excelente|

**Armazenamento**: MÃ­nimo 50GB (especialmente para Stable Diffusion)

## ğŸ”„ Atualizar Modelos

```bash
# Puxar novos modelos Ollama
ollama pull llama2
ollama pull neural-chat

# Listar modelos instalados
ollama list

# Remover modelo
ollama rm mistral
```

## ğŸ“ Estrutura de SaÃ­da

```
output/
â”œâ”€â”€ 20240127_153000_Seu_Tema/
â”‚   â”œâ”€â”€ plan.json                  # Planejamento
â”‚   â”œâ”€â”€ script.md                  # Roteiro
â”‚   â”œâ”€â”€ image_prompts.json         # Prompts otimizados
â”‚   â”œâ”€â”€ subtitles.srt              # Legendas (SRT)
â”‚   â”œâ”€â”€ subtitles.vtt              # Legendas (VTT)
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ scene_001.png
â”‚   â”‚   â”œâ”€â”€ scene_002.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â””â”€â”€ narration.wav
â”‚   â”œâ”€â”€ video_final.mp4            # VÃ­deo final
â”‚   â”œâ”€â”€ pipeline.log               # Log detalhado
â”‚   â””â”€â”€ pipeline_results.json      # Resumo dos resultados
```

## ğŸ¯ PrÃ³ximos Passos

1. Executar pipeline teste: `make full TOPIC="Teste"`
2. Verificar saÃ­da em `output/`
3. Customizar prompts em `config/prompts.yaml`
4. Ajustar timings de narraÃ§Ã£o em scripts
5. Explorar diferentes modelos e qualidades

## ğŸ“š Mais InformaÃ§Ãµes

- [ARCHITECTURE.md](./ARCHITECTURE.md) - Detalhes tÃ©cnicos
- [EXAMPLES.md](./EXAMPLES.md) - Exemplos de uso
- [config/models.yaml](../config/models.yaml) - ConfiguraÃ§Ãµes de modelos
- [config/prompts.yaml](../config/prompts.yaml) - Templates de prompts
